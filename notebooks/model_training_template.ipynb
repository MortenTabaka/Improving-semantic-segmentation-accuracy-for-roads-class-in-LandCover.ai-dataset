{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:25:57.533003Z",
     "start_time": "2023-04-08T18:25:56.375728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f4408013a58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "\n",
    "ABS_PATH = %pwd\n",
    "notebook_path = [idx for idx,ch in enumerate(ABS_PATH) if ch=='/']\n",
    "notebooks_level_in_the_project = 1\n",
    "\n",
    "PROJECT_PATH = ABS_PATH[:notebook_path[-notebooks_level_in_the_project]]\n",
    "if PROJECT_PATH not in sys.path:\n",
    "    sys.path.append(PROJECT_PATH)\n",
    "\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8810a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:25:59.116721Z",
     "start_time": "2023-04-08T18:25:58.774241Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data.requests_downloader import UrlDownloader\n",
    "from src.features.dataset import Dataset\n",
    "from src.features.metrics import CustomMeanIoU\n",
    "from src.models.model_builder import Model\n",
    "from src.visualization.visualize import PredictionMasks\n",
    "from src.features.evaluation_utils import (\n",
    "    PredictionIoU,\n",
    "    ConfusionMatrix,\n",
    "    HistoryUtilities,\n",
    "    History\n",
    ")\n",
    "from src.features.loss_functions import SemanticSegmentationLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:25:59.308050Z",
     "start_time": "2023-04-08T18:25:59.266948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.5.1\n",
      "\n",
      "Python 3.6.9 (default, Jan 26 2021, 15:33:00) \n",
      "[GCC 8.4.0]\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07420b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:25:59.531893Z",
     "start_time": "2023-04-08T18:25:59.531704Z"
    }
   },
   "outputs": [],
   "source": [
    "VERSION = '10.0'\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file 'models/scripts/run_prediction_on_folder.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! python3 models/scripts/run_prediction_on_folder.py --checkpoint-to-load \"/app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eccb38",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:25:59.871926Z",
     "start_time": "2023-04-08T18:25:59.869542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously unzipped files exists.\n"
     ]
    }
   ],
   "source": [
    "UrlDownloader().download_project_preprocessed_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "465e97b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:00.234126Z",
     "start_time": "2023-04-08T18:26:00.052965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: <BatchDataset shapes: ((4, 512, 512, 3), (4, 512, 512, 5)), types: (tf.float32, tf.float32)>\n",
      "Number of images in Train Dataset: 7468\n",
      "Val Dataset: <BatchDataset shapes: ((4, 512, 512, 3), (4, 512, 512, 5)), types: (tf.float32, tf.float32)>\n",
      "Number of images in Val Dataset: 1600\n",
      "Test Dataset: <BatchDataset shapes: ((4, 512, 512, 3), (4, 512, 512, 5)), types: (tf.float32, tf.float32)>\n",
      "Number of images in Val Dataset: 1600\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = os.path.join(PROJECT_PATH, 'data/processed')\n",
    "landcover_dataset = Dataset(DATASET_PATH, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES, BATCH_SIZE)\n",
    "train_dataset, val_dataset, test_dataset = landcover_dataset.generate_datasets()\n",
    "\n",
    "print(\"Train Dataset:\", train_dataset)\n",
    "print(\"Number of images in Train Dataset:\", BATCH_SIZE * len(train_dataset))\n",
    "print(\"Val Dataset:\", val_dataset)\n",
    "print(\"Number of images in Val Dataset:\", BATCH_SIZE * len(val_dataset))\n",
    "print(\"Test Dataset:\", test_dataset)\n",
    "print(\"Number of images in Val Dataset:\", BATCH_SIZE * len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27281b13",
   "metadata": {},
   "source": [
    "# Class balance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4ffc57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:00.663424Z",
     "start_time": "2023-04-08T18:26:00.429054Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_number</th>\n",
       "      <th>pixel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>background</th>\n",
       "      <td>0</td>\n",
       "      <td>1.626436e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>1</td>\n",
       "      <td>2.456691e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woodland</th>\n",
       "      <td>2</td>\n",
       "      <td>9.256445e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>3</td>\n",
       "      <td>1.757691e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roads</th>\n",
       "      <td>4</td>\n",
       "      <td>4.570887e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            class_number   pixel_count\n",
       "background             0  1.626436e+09\n",
       "buildings              1  2.456691e+07\n",
       "woodland               2  9.256445e+08\n",
       "water                  3  1.757691e+08\n",
       "roads                  4  4.570887e+07"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "landcover_dataset.get_dataframe_of_previously_calculated_class_balance_class_balance().plot.bar(y=\"pixel_count\", xlabel=\"Class name\", ylabel=\"Count\")\n",
    "landcover_dataset.get_dataframe_of_previously_calculated_class_balance_class_balance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c91706",
   "metadata": {},
   "source": [
    "# Evaluation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d76047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:00.859867Z",
     "start_time": "2023-04-08T18:26:00.815528Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_mIoU_metric = CustomMeanIoU(num_classes=NUM_CLASSES, name='mIoU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2290e4",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "### Model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "750b5074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:01.283864Z",
     "start_time": "2023-04-08T18:26:01.243495Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_folders(paths: List[str]):\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737c4322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:01.595938Z",
     "start_time": "2023-04-08T18:26:01.595745Z"
    }
   },
   "outputs": [],
   "source": [
    "path_best_dice_loss = PROJECT_PATH + f'/notebooks/templates/results/DeepLabv3+/{VERSION}/best_dice_loss/checkpoint'\n",
    "dir_path_dice_loss= PROJECT_PATH + f'/notebooks/templates/results/DeepLabv3+/{VERSION}/best_dice_loss'\n",
    "path_best_miou = PROJECT_PATH + f'/notebooks/templates/results/DeepLabv3+/{VERSION}/best_miou/checkpoint'\n",
    "dir_path_miou = PROJECT_PATH + f'/notebooks/templates/results/DeepLabv3+/{VERSION}/best_miou'\n",
    "\n",
    "\n",
    "create_folders([\n",
    "    dir_path_dice_loss,\n",
    "    dir_path_miou,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b6d567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:01.772406Z",
     "start_time": "2023-04-08T18:26:01.768716Z"
    }
   },
   "outputs": [],
   "source": [
    "best_val_loss = tf.keras.callbacks.ModelCheckpoint(\n",
    "    path_best_dice_loss,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "best_miou = tf.keras.callbacks.ModelCheckpoint(\n",
    "    path_best_miou,\n",
    "    monitor='val_mIoU',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='max',\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a495e73",
   "metadata": {},
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7239ada7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:02.219091Z",
     "start_time": "2023-04-08T18:26:02.212715Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping_val_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                           patience=3,\n",
    "                                                           mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a948e",
   "metadata": {},
   "source": [
    "### Learning rate schedule [optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04dab938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:02.654891Z",
     "start_time": "2023-04-08T18:26:02.649978Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "NUM_TRAIN_IMAGES = BATCH_SIZE * len(train_dataset)\n",
    "NUM_VAL_IMAGES = BATCH_SIZE * len(val_dataset)\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "final_learning_rate = 0.0001\n",
    "learning_rate_decay_factor = (final_learning_rate / initial_learning_rate) ** (1/EPOCHS)\n",
    "steps_per_epoch = int(NUM_TRAIN_IMAGES/BATCH_SIZE)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=initial_learning_rate,\n",
    "                decay_steps=steps_per_epoch,\n",
    "                decay_rate=learning_rate_decay_factor,\n",
    "                staircase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ab5da",
   "metadata": {},
   "source": [
    "### Get current lr [metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8a20742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:03.160692Z",
     "start_time": "2023-04-08T18:26:03.155855Z"
    }
   },
   "outputs": [],
   "source": [
    "#  https://stackoverflow.com/questions/47490834/how-can-i-print-the-learning-rate-at-each-epoch-with-adam-optimizer-in-keras\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer._decayed_lr(tf.float32)\n",
    "    return lr\n",
    "\n",
    "optimizer_adam = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "lr_metric = get_lr_metric(optimizer_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e8b583",
   "metadata": {},
   "source": [
    "## Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbd9b7df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:03.597022Z",
     "start_time": "2023-04-08T18:26:03.592645Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating a model\n",
    "WEIGHTS = \"cityscapes\"\n",
    "SHOULD_FREEZE_LAYERS = True\n",
    "LAST_LAYER_TO_FREEZE = 359  # All from the begining up to 359 will be frozen\n",
    "ACTIVATION = \"softmax\"\n",
    "DEEPLAB_VERSION = \"deeplabv3plus\"\n",
    "OUTPUT_STRIDE = 16  # or 8\n",
    "\n",
    "# compiling the model\n",
    "if optimizer_adam:\n",
    "    OPTIMIZER = optimizer_adam\n",
    "else:\n",
    "    OPTIMIZER = tf.keras.optimizers.Adam(initial_learning_rate)\n",
    "\n",
    "LOSS = SemanticSegmentationLoss(NUM_CLASSES).soft_dice_loss\n",
    "METRICS = [\"accuracy\", custom_mIoU_metric]\n",
    "\n",
    "# training the model\n",
    "EPOCHS = 40\n",
    "TRAINING_DATA_PATH = PROJECT_PATH + f'/notebooks/templates/results/DeepLabv3+/{VERSION}'\n",
    "CALLBACKS = [\n",
    "    early_stopping_val_loss,\n",
    "    best_val_loss,\n",
    "    best_miou\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685c880",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DeepLabv3+ model architecture\n",
    "\n",
    "https://keras.io/examples/vision/deeplabv3_plus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:04.357322Z",
     "start_time": "2023-04-08T18:26:04.355292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.0.1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revision = f\"{VERSION}.1\"\n",
    "revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T18:26:07.223934Z",
     "start_time": "2023-04-08T18:26:04.675984Z"
    }
   },
   "outputs": [],
   "source": [
    "deeplab_model = Model(\n",
    "    revision=revision,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    input_image_height=IMG_HEIGHT,\n",
    "    input_image_width=IMG_WIDTH,\n",
    "    number_of_classes=NUM_CLASSES,\n",
    "    pretrained_weights=WEIGHTS,\n",
    "    do_freeze_layers=SHOULD_FREEZE_LAYERS,\n",
    "    last_layer_frozen=LAST_LAYER_TO_FREEZE,\n",
    "    activation=ACTIVATION,\n",
    "    model_architecture=DEEPLAB_VERSION,\n",
    "    output_stride=OUTPUT_STRIDE,\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss_function=LOSS,\n",
    "    metrics=METRICS\n",
    ")\n",
    "deeplab_model.save_model_revision(\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        final_learning_rate=final_learning_rate\n",
    ")\n",
    "\n",
    "model = deeplab_model.get_deeplab_model()\n",
    "model.compile(*deeplab_model.get_compile_parameters)\n",
    "\n",
    "# tf.keras.utils.plot_model(model, to_file=data_save_dir + '/Deeplabv3plus_v8_5.jpg', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1867/1867 [==============================] - 499s 265ms/step - loss: 0.6838 - accuracy: 0.7721 - mIoU: 0.4540 - val_loss: 0.6700 - val_accuracy: 0.7962 - val_mIoU: 0.4956\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66997, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00001: val_mIoU improved from -inf to 0.49559, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_miou/checkpoint\n",
      "Epoch 2/40\n",
      "1867/1867 [==============================] - 497s 266ms/step - loss: 0.6516 - accuracy: 0.8444 - mIoU: 0.5601 - val_loss: 0.6760 - val_accuracy: 0.8002 - val_mIoU: 0.5264\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.66997\n",
      "\n",
      "Epoch 00002: val_mIoU improved from 0.49559 to 0.52639, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_miou/checkpoint\n",
      "Epoch 3/40\n",
      "1867/1867 [==============================] - 500s 268ms/step - loss: 0.6340 - accuracy: 0.8757 - mIoU: 0.6201 - val_loss: 0.6676 - val_accuracy: 0.8174 - val_mIoU: 0.5445\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66997 to 0.66760, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00003: val_mIoU improved from 0.52639 to 0.54455, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_miou/checkpoint\n",
      "Epoch 4/40\n",
      "1867/1867 [==============================] - 499s 267ms/step - loss: 0.6211 - accuracy: 0.8939 - mIoU: 0.6592 - val_loss: 0.6593 - val_accuracy: 0.8420 - val_mIoU: 0.5654\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.66760 to 0.65932, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00004: val_mIoU improved from 0.54455 to 0.56540, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_miou/checkpoint\n",
      "Epoch 5/40\n",
      "1867/1867 [==============================] - 518s 277ms/step - loss: 0.5350 - accuracy: 0.8999 - mIoU: 0.6040 - val_loss: 0.5105 - val_accuracy: 0.8506 - val_mIoU: 0.4946\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65932 to 0.51052, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00005: val_mIoU did not improve from 0.56540\n",
      "Epoch 6/40\n",
      "1867/1867 [==============================] - 504s 270ms/step - loss: 0.4623 - accuracy: 0.9099 - mIoU: 0.5837 - val_loss: 0.5109 - val_accuracy: 0.8581 - val_mIoU: 0.5023\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.51052\n",
      "\n",
      "Epoch 00006: val_mIoU did not improve from 0.56540\n",
      "Epoch 7/40\n",
      "1867/1867 [==============================] - 504s 270ms/step - loss: 0.4552 - accuracy: 0.9174 - mIoU: 0.5994 - val_loss: 0.5059 - val_accuracy: 0.8662 - val_mIoU: 0.5144\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.51052 to 0.50586, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00007: val_mIoU did not improve from 0.56540\n",
      "Epoch 8/40\n",
      "1867/1867 [==============================] - 497s 266ms/step - loss: 0.4502 - accuracy: 0.9224 - mIoU: 0.6089 - val_loss: 0.5054 - val_accuracy: 0.8669 - val_mIoU: 0.5071\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.50586 to 0.50536, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00008: val_mIoU did not improve from 0.56540\n",
      "Epoch 9/40\n",
      "1867/1867 [==============================] - 502s 269ms/step - loss: 0.4293 - accuracy: 0.9215 - mIoU: 0.5879 - val_loss: 0.4228 - val_accuracy: 0.8734 - val_mIoU: 0.4446\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.50536 to 0.42276, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00009: val_mIoU did not improve from 0.56540\n",
      "Epoch 10/40\n",
      "1867/1867 [==============================] - 519s 278ms/step - loss: 0.3780 - accuracy: 0.9213 - mIoU: 0.5099 - val_loss: 0.4219 - val_accuracy: 0.8677 - val_mIoU: 0.4412\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.42276 to 0.42191, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00010: val_mIoU did not improve from 0.56540\n",
      "Epoch 11/40\n",
      "1867/1867 [==============================] - 513s 275ms/step - loss: 0.3532 - accuracy: 0.9200 - mIoU: 0.4999 - val_loss: 0.2937 - val_accuracy: 0.8357 - val_mIoU: 0.3090\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.42191 to 0.29371, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00011: val_mIoU did not improve from 0.56540\n",
      "Epoch 12/40\n",
      "1867/1867 [==============================] - 503s 269ms/step - loss: 0.2597 - accuracy: 0.8719 - mIoU: 0.3392 - val_loss: 0.2895 - val_accuracy: 0.8422 - val_mIoU: 0.3132\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29371 to 0.28953, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00012: val_mIoU did not improve from 0.56540\n",
      "Epoch 13/40\n",
      "1867/1867 [==============================] - 499s 267ms/step - loss: 0.2556 - accuracy: 0.8823 - mIoU: 0.3715 - val_loss: 0.2883 - val_accuracy: 0.8527 - val_mIoU: 0.3692\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28953 to 0.28829, saving model to /app/notebooks/templates/results/DeepLabv3+/10.0/best_dice_loss/checkpoint\n",
      "\n",
      "Epoch 00013: val_mIoU did not improve from 0.56540\n",
      "Epoch 14/40\n",
      "1867/1867 [==============================] - 511s 273ms/step - loss: 0.2462 - accuracy: 0.9020 - mIoU: 0.4359 - val_loss: 0.2888 - val_accuracy: 0.8435 - val_mIoU: 0.3253\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28829\n",
      "\n",
      "Epoch 00014: val_mIoU did not improve from 0.56540\n",
      "Epoch 15/40\n",
      " 240/1867 [==>...........................] - ETA: 6:32 - loss: 0.2184 - accuracy: 0.9086 - mIoU: 0.4504"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-95d6218f5f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCALLBACKS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 _r=1):\n\u001b[1;32m   1177\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=CALLBACKS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccdccc",
   "metadata": {},
   "source": [
    "### Save history to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bff2a581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-431179f9ddb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory_utils\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHistoryUtilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_model_history_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAINING_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_history_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history_utils = HistoryUtilities()\n",
    "history_utils.dump_model_history_to_file(history, TRAINING_DATA_PATH, \"history\")\n",
    "\n",
    "History([history]).display_history_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc9e6e",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fdf314e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcb206e6e80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(path_best_dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b8285",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_every_class = PredictionIoU(model, test_dataset, NUM_CLASSES).get_iou_for_every_class()\n",
    "iou_every_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictionMasks(model, landcover_dataset, NUM_CLASSES).display_overlay_predictions_for_test_set(4, (25, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aed2de",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f1dec4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-463789fe607f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/app/src/features/evaluation_utils.py\u001b[0m in \u001b[0;36mdisplay_confusion_matrix\u001b[0;34m(self, class_names)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mdf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Normalize the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/src/features/evaluation_utils.py\u001b[0m in \u001b[0;36mget_dataframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msingle_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_predictions_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             matrix = tf.math.confusion_matrix(\n",
      "\u001b[0;32m/app/src/features/evaluation_utils.py\u001b[0m in \u001b[0;36mget_predictions_and_labels\u001b[0;34m(self, single_batch)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_predictions_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1720\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_names = ['background', 'buildings', 'woodland', 'water', 'roads']\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(model, test_dataset, NUM_CLASSES)\n",
    "confusion_matrix.display_confusion_matrix(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "732ffe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 63s 157ms/step - loss: 0.2981 - accuracy: 0.8467 - mIoU: 0.3722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29807135462760925, 0.8466689586639404, 0.37224510312080383]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662ebce",
   "metadata": {},
   "source": [
    "# Further training the model\n",
    "## You may change the settings\n",
    "E.g. Freeze less layers, change optimizer's learning rate, add metric, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:24:45.772235Z",
     "start_time": "2023-04-01T13:24:45.729731Z"
    }
   },
   "outputs": [],
   "source": [
    "break\n",
    "revision = f\"{VERSION}.2\"\n",
    "revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T21:41:52.145128Z",
     "start_time": "2023-04-01T21:41:48.596914Z"
    }
   },
   "outputs": [],
   "source": [
    "deeplab_model = Model(\n",
    "    revision=revision,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    input_image_height=IMG_HEIGHT,\n",
    "    input_image_width=IMG_WIDTH,\n",
    "    number_of_classes=NUM_CLASSES,\n",
    "    pretrained_weights=WEIGHTS,\n",
    "    do_freeze_layers=SHOULD_FREEZE_LAYERS,\n",
    "    last_layer_frozen=LAST_LAYER_TO_FREEZE,  # freeze 40 layers less\n",
    "    activation=ACTIVATION,\n",
    "    model_architecture=DEEPLAB_VERSION,\n",
    "    output_stride=OUTPUT_STRIDE,\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss_function=LOSS,\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "deeplab_model.save_model_revision(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    final_learning_rate=final_learning_rate\n",
    ")\n",
    "\n",
    "model = deeplab_model.get_deeplab_model()\n",
    "model.compile(*deeplab_model.get_compile_parameters)\n",
    "model.load_weights(path_best_dice_loss)\n",
    "\n",
    "# tf.keras.utils.plot_model(model, to_file=data_save_dir + '/Deeplabv3plus_v8_5.jpg', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6630f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights with best results\n",
    "history_2 = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=EPOCHS,\n",
    "    callbacks=CALLBACKS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25dd0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "History([history, history_2]).display_history_plots(TRAINING_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f3877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
