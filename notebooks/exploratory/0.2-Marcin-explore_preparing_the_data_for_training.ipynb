{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4edbf4c9",
   "metadata": {},
   "source": [
    "This notebook is based on a notebook from [lesson](https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow/ungradedLab/Wlfvj/implement-a-fully-convolutional-neural-network) in course \"Advanced Computer Vision with TensorFlow\" by DeepLearning.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd4f28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f69e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = ['background', 'building', 'woodland', 'water', 'road']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ee8c9",
   "metadata": {},
   "source": [
    "## Load and prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a437e3a6",
   "metadata": {},
   "source": [
    "Dataset classes names and corresponding values for pixels in masks are shown below.\n",
    "\n",
    "| Value  | Class Name    |\n",
    "| -------| -------------| \n",
    "| 0      | background |\n",
    "| 1      | building      |\n",
    "| 2      | woodland      |\n",
    "| 3      | water |\n",
    "| 4      | road     |\n",
    "\n",
    "Each mask has shape `(512, 512, 3)` where third channel is responsible for providing information about class to which particular pixel belongs. \n",
    "\n",
    "For example if we'll acces pixel of road **`mask_as_array[height, width, :]`** the result will be list **`[4, 4, 4]`** denoting pixel class.\n",
    "\n",
    "For further explanation open [notebook](https://github.com/MortenTabaka/roads-semantic-segmentation-in-LandCover.ai-dataset_graduate-thesis/blob/main/notebooks/exploratory/0.1-Marcin-verify_mask_convention_for_classes.ipynb).\n",
    "\n",
    "For this project label mask will be reshaped from `(height, width, 3)` to `(height, width, num_of_classes)` with each slice along the third axis having `1` if it belongs to the class corresponding to that slice's index else `0`.\n",
    "\n",
    "So if a pixel is part of a road, then **`mask_as_array[height, width, :] = [0, 0, 0, 0, 1]`**\n",
    "\n",
    "The project is aiming to distinguish roads and everything else, then there will be only two classes: **background** and **road**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e53650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['background', 'road']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_filename_to_image_and_mask(t_filename, a_filename):\n",
    "    '''\n",
    "    Preprocesses the dataset by:\n",
    "        * resizing the input image and label maps\n",
    "        * normalizing the input image pixels\n",
    "        * reshaping the label maps from (height, width, 3) to (height, width, 2)\n",
    "\n",
    "    Args:\n",
    "        t_filename (string) -- path to the raw input image\n",
    "        a_filename (string) -- path to the raw annotation (label map) file\n",
    "\n",
    "    Returns:\n",
    "        image (tensor) -- preprocessed image\n",
    "        annotation (tensor) -- preprocessed annotation\n",
    "    '''\n",
    "    # Convert image and mask files to tensors \n",
    "    img_raw = tf.io.read_file(t_filename)\n",
    "    anno_raw = tf.io.read_file(a_filename)\n",
    "    image = tf.io.decode_jpeg(img_raw)\n",
    "    annotation = tf.io.decode_png(anno_raw)\n",
    "    \n",
    "    # Resize image and segmentation mask\n",
    "    image = tf.image.resize(image, (height, width,))\n",
    "    annotation = tf.image.resize(annotation, (height, width,))\n",
    "    image = tf.reshape(image, (height, width, 3,))\n",
    "    annotation = tf.cast(annotation, dtype=tf.int32)\n",
    "    annotation = tf.reshape(annotation, (height, width, 1,))\n",
    "    stack_list = []\n",
    "\n",
    "    # Reshape segmentation masks\n",
    "    for c in range(len(class_names)):\n",
    "        mask = tf.equal(annotation[:,:,0], tf.constant(c))\n",
    "        stack_list.append(tf.cast(mask, dtype=tf.int32))\n",
    "\n",
    "    annotation = tf.stack(stack_list, axis=2)\n",
    "\n",
    "    # Normalize pixels in the input image\n",
    "    image = image/127.5\n",
    "    image -= 1\n",
    "\n",
    "    return image, annotation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU (Python 3.7)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
