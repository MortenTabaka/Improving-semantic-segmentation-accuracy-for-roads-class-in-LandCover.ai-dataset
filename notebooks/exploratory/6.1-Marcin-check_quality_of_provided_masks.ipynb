{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71bb075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab173bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "IMG_SIZE = 512\n",
    "\n",
    "MASK_SIZE = 512\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "NUM_TRAIN_IMAGES = 7470\n",
    "\n",
    "NUM_VAL_IMAGES = 1602\n",
    "\n",
    "NUM_TEST_IMAGES = 1602"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f310e60",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e3dd70",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_absolute_path_to_project():\n",
    "    abs_path = %pwd\n",
    "\n",
    "    slash_idx = [idx for idx,ch in enumerate(abs_path) if ch=='/']\n",
    "\n",
    "    abs_path = abs_path[:slash_idx[-2]]\n",
    "    \n",
    "    return abs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c4d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABS_PATH = get_absolute_path_to_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5ce277",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ABS_PATH + '/data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86db0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = DATA_DIR + '/train'\n",
    "VAL_PATH = DATA_DIR + '/val'\n",
    "TEST_PATH = DATA_DIR + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015d6498",
   "metadata": {
    "code_folding": [
     8,
     23,
     28,
     35
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_images = sorted(glob(os.path.join(TRAIN_PATH, \"images/img/*\")))\n",
    "train_masks = sorted(glob(os.path.join(TRAIN_PATH, \"masks/img/*\")))\n",
    "val_images = sorted(glob(os.path.join(VAL_PATH, \"images/img/*\")))\n",
    "val_masks = sorted(glob(os.path.join(VAL_PATH, \"masks/img/*\")))\n",
    "test_images = sorted(glob(os.path.join(TEST_PATH, \"images/img/*\")))\n",
    "test_masks = sorted(glob(os.path.join(TEST_PATH, \"masks/img/*\")))\n",
    "\n",
    "\n",
    "def read_image(image_path, mask=False):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    if mask:\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        image = image[..., 0]\n",
    "        image = tf.reshape(image, (MASK_SIZE, MASK_SIZE, 1))\n",
    "        image.set_shape([None, None, 1])\n",
    "        image = tf.image.resize(images=image, size=[MASK_SIZE, MASK_SIZE])\n",
    "    else:\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image.set_shape([None, None, 3])\n",
    "        image = tf.image.resize(images=image, size=[IMG_SIZE, IMG_SIZE])\n",
    "        image = image / 255.\n",
    "    return image\n",
    "\n",
    "def load_data(image_list, mask_list):\n",
    "    image = read_image(image_list)\n",
    "    mask = read_image(mask_list, mask=True)\n",
    "    return image, mask\n",
    "\n",
    "def load_augmented_data(image_list, mask_list):\n",
    "    image = read_image(image_list)\n",
    "    mask = read_image(mask_list, mask=True)\n",
    "    image, mask = augmentation(image, mask)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def data_generator(image_list, mask_list, augmentation=False, factor=1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns augmented or not augmented dataset with the same amount of elements.\n",
    "    \n",
    "    Args:\n",
    "    image_list: list of paths to each image\n",
    "    mask_list: list of paths to corresponding masks of images (sorted)\n",
    "    augmentation: \"True\" for getting augmeneted images and masks\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
    "    \n",
    "    if augmentation:\n",
    "        dataset = dataset.map(load_augmented_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    else:\n",
    "        dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        \n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    \n",
    "    if factor > 1 and augmentation:\n",
    "        for _ in range(factor-1):\n",
    "            dataset_to_concat = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
    "            dataset_to_concat = dataset_to_concat.map(load_augmented_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            dataset_to_concat = dataset_to_concat.batch(BATCH_SIZE, drop_remainder=True)\n",
    "            \n",
    "            dataset = dataset.concatenate(dataset_to_concat)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1776736e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: <BatchDataset shapes: ((2, 512, 512, 3), (2, 512, 512, 1)), types: (tf.float32, tf.float32)>\n",
      "Number of images in Train Dataset: 7470\n",
      "Val Dataset: <BatchDataset shapes: ((2, 512, 512, 3), (2, 512, 512, 1)), types: (tf.float32, tf.float32)>\n",
      "Number of images in Val Dataset: 1602\n",
      "Test Dataset: <BatchDataset shapes: ((2, 512, 512, 3), (2, 512, 512, 1)), types: (tf.float32, tf.float32)>\n",
      "Number of images in Val Dataset: 1602\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_generator(train_images, train_masks)\n",
    "val_dataset = data_generator(val_images, val_masks)\n",
    "test_dataset = data_generator(test_images, test_masks)\n",
    "\n",
    "print(\"Train Dataset:\", train_dataset)\n",
    "print(\"Number of images in Train Dataset:\", BATCH_SIZE * len(train_dataset))\n",
    "print(\"Val Dataset:\", val_dataset)\n",
    "print(\"Number of images in Val Dataset:\", BATCH_SIZE * len(val_dataset))\n",
    "print(\"Test Dataset:\", test_dataset)\n",
    "print(\"Number of images in Val Dataset:\", BATCH_SIZE * len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db4485",
   "metadata": {},
   "source": [
    "# Image utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733c4b2c",
   "metadata": {
    "code_folding": [
     0,
     7,
     20,
     30,
     40
    ]
   },
   "outputs": [],
   "source": [
    "def infer(model, image_tensor):\n",
    "    predictions = model.predict(np.expand_dims((image_tensor), axis=0))\n",
    "    predictions = np.squeeze(predictions)\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def decode_segmentation_masks(mask, colormap, n_classes):\n",
    "    r = np.zeros_like(mask).astype(np.uint8)\n",
    "    g = np.zeros_like(mask).astype(np.uint8)\n",
    "    b = np.zeros_like(mask).astype(np.uint8)\n",
    "    for l in range(0, n_classes):\n",
    "        idx = mask == l\n",
    "        r[idx] = colormap[l][0]\n",
    "        g[idx] = colormap[l][1]\n",
    "        b[idx] = colormap[l][2]\n",
    "    rgb = np.stack([r, g, b], axis=2)\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def get_overlay(image, colored_mask):\n",
    "    image = tf.keras.preprocessing.image.array_to_img(image)\n",
    "    image = np.array(image).astype(np.uint8)\n",
    "    image = tf.image.resize(image, [512, 512])\n",
    "    image.set_shape([None, None, 3])\n",
    "    image = tf.reshape(image, (512,512,3))\n",
    "    overlay = tfa.image.blend(image, colored_mask, 0.5)\n",
    "    return overlay\n",
    "\n",
    "\n",
    "def plot_samples_matplotlib(display_list, figsize=(5, 3)):\n",
    "    _, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
    "    for i in range(len(display_list)):\n",
    "        if display_list[i].shape[-1] == 3:\n",
    "            axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        else:\n",
    "            axes[i].imshow(display_list[i])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_predictions(images_list, masks_list, colormap, model):\n",
    "    for image_file, mask_file in zip(images_list, masks_list):\n",
    "        image_tensor = read_image(image_file)\n",
    "        mask_tensor = read_image(mask_file, mask=True)\n",
    "        mask_tensor = mask_tensor[..., 0]\n",
    "        mask_tensor = decode_segmentation_masks(mask_tensor, colormap, NUM_CLASSES)\n",
    "        prediction_mask = infer(image_tensor=image_tensor, model=model)\n",
    "        prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, NUM_CLASSES)\n",
    "        overlay = get_overlay(image_tensor, prediction_colormap)\n",
    "        overlay_orginal = get_overlay(image_tensor, mask_tensor)\n",
    "        plot_samples_matplotlib(\n",
    "            [image_tensor, overlay_orginal, overlay, prediction_colormap], figsize=(18, 14)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2734fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_colormap = [[0, 0, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 255]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffbd994",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07aa96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_weights_path = ABS_PATH + f'/models/saved_weights/deeplabv3plus_v5.10.h5'\n",
    "saved_weights_dir= ABS_PATH + f'/models/saved_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766fe206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional module import path\n",
    "\n",
    "module_path = ABS_PATH + '/src/models'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f906bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplabv3plus import Deeplabv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68c7fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deeplab_model(weights=None, freeze_conv_base=True, freeze_border=359, activation=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "    weights: one of 'pascal_voc' (pre-trained on pascal voc),\n",
    "            'cityscapes' (pre-trained on cityscape) or None (random initialization)\n",
    "    freeze_conv_base: True if convolution base should be freezed or \n",
    "            False if it to be otherwise\n",
    "    activation: optional activation to add to the top of the network.\n",
    "            One of 'softmax', 'sigmoid' or None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Deeplabv3(\n",
    "        weights=weights,\n",
    "        classes=NUM_CLASSES,\n",
    "        backbone='xception',\n",
    "        OS=16,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        activation=activation)\n",
    "    \n",
    "    if freeze_conv_base:\n",
    "        \n",
    "        for i, layer in enumerate(model.layers):\n",
    "            \n",
    "            if i < freeze_border:\n",
    "                layer.trainable=False\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa31529f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = get_deeplab_model(weights='cityscapes', freeze_conv_base=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a67ecb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(saved_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945d2bd",
   "metadata": {},
   "source": [
    "# Find which of predicted masks have low meanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23f7c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_split = ['train', 'test', 'val']\n",
    "\n",
    "for split in ds_split:\n",
    "    path = ABS_PATH + f'/data/evaluation_of_masks/{split}'\n",
    "    if not os.path.exists(path):      \n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e346107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples_matplotlib(display_list, miou_score, save_path, figsize=(5, 3)):\n",
    "    \n",
    "    sub_names = ['Image', 'Image-Ground truth overlay', 'Image-predicted mask overlay', 'Ground truth mask', 'Predicted mask']\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
    "    \n",
    "    for i in range(len(display_list)):\n",
    "#         axes[i].title.set_text(sub_names[i])\n",
    "        axes[i].set_title(sub_names[i], size=16)\n",
    "        axes[i].axis('off')\n",
    "        if display_list[i].shape[-1] == 3:\n",
    "            axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        else:\n",
    "            axes[i].imshow(display_list[i])\n",
    "            \n",
    "    fig.suptitle('meanIoU = {0:.2f}%'.format(miou_score*100), fontsize=20)\n",
    "    fig.savefig(save_path)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a28fd24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image_tensor, mask_tensor, prediction_mask, miou_score, save_path, colormap):\n",
    "   \n",
    "    mask_tensor = decode_segmentation_masks(mask_tensor, colormap, NUM_CLASSES)\n",
    "    prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, NUM_CLASSES)\n",
    "    overlay = get_overlay(image_tensor, prediction_colormap)\n",
    "    overlay_orginal = get_overlay(image_tensor, mask_tensor)\n",
    "    save_samples_matplotlib(\n",
    "        [image_tensor, overlay_orginal, overlay, mask_tensor, prediction_colormap],\n",
    "        miou_score,\n",
    "        save_path,\n",
    "        figsize=(32, 7)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92926dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_save_image_mask_miou_below_threshold(images_list,\n",
    "                                                masks_list,\n",
    "                                                which_ds_part,\n",
    "                                                predictive_model,\n",
    "                                                threshold=0.2):\n",
    "\n",
    "    m = tf.keras.metrics.MeanIoU(NUM_CLASSES)\n",
    "    \n",
    "    image_mask_miou = [[], [], []]\n",
    "    \n",
    "    for image_file, mask_file in zip(images_list, masks_list):\n",
    "        \n",
    "        m.reset_state()\n",
    "        \n",
    "        image_tensor = read_image(image_file)\n",
    "        \n",
    "        mask_tensor = read_image(mask_file, mask=True)\n",
    "        mask_tensor = mask_tensor[..., 0]\n",
    "\n",
    "        prediction_mask = infer(image_tensor=image_tensor, model=predictive_model)\n",
    "        \n",
    "        m.update_state([mask_tensor],\n",
    "                       [prediction_mask])\n",
    "        \n",
    "        miou_score = m.result().numpy()\n",
    "        \n",
    "        if miou_score < threshold:\n",
    "            \n",
    "            for i, element in enumerate([image_file, mask_file, miou_score]):\n",
    "                image_mask_miou[i].append(element)\n",
    "                \n",
    "            slash_idx = [idx for idx,ch in enumerate(image_file) if ch=='/']\n",
    "            f_name = image_file[slash_idx[-1]:]\n",
    "\n",
    "            save_path = ABS_PATH + f'/data/evaluation_of_masks/{which_ds_part}{f_name}'\n",
    "            \n",
    "            save_image(image_tensor,\n",
    "                       mask_tensor,\n",
    "                       prediction_mask,\n",
    "                       miou_score,\n",
    "                       save_path,\n",
    "                       custom_colormap)\n",
    "    \n",
    "    return image_mask_miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a040aded",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_mask_miou_train_dataset = get_and_save_image_mask_miou_below_threshold(train_images,\n",
    "                                                                           train_masks,\n",
    "                                                                           which_ds_part='train',\n",
    "                                                                           predictive_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0728651c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "image_mask_miou_val_dataset = get_and_save_image_mask_miou_below_threshold(val_images,\n",
    "                                                                           val_masks,\n",
    "                                                                           which_ds_part='val',\n",
    "                                                                           predictive_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b32f9e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_mask_miou_test_dataset = get_and_save_image_mask_miou_below_threshold(test_images,\n",
    "                                                                           test_masks,\n",
    "                                                                           which_ds_part='test',\n",
    "                                                                           predictive_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb586248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file_paths_to_txt(image_mask_miou_all_parts):\n",
    "\n",
    "    dataset_split = ['train', 'val', 'test']\n",
    "    data_type = ['images', 'masks', 'mious']\n",
    "    \n",
    "    for split, lists in zip(dataset_split, image_mask_miou_all_parts):\n",
    "        \n",
    "        for d_type, list_to_save in zip(data_type, lists):\n",
    "            \n",
    "            save_path = ABS_PATH + f'/data/evaluation_of_masks/{split}_{d_type}_to_exclude.txt'\n",
    "            \n",
    "            with open(save_path, 'w') as f:\n",
    "                for item in list_to_save:\n",
    "                    f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55ed3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_paths_to_txt([image_mask_miou_train_dataset, image_mask_miou_val_dataset, image_mask_miou_test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b999d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5127175368139223"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_mask_miou_train_dataset[0]) / len(train_images) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd049b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8726591760299627"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_mask_miou_val_dataset[0]) / len(val_images) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e33569ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8726591760299627"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_mask_miou_test_dataset[0]) / len(test_images) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU (Python 3.7)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
